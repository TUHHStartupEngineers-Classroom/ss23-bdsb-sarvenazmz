[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "1 Tidyverse Challenge-1\n\n#----1.libraries----\nlibrary(tidyverse)\nlibrary(readxl)\n\n# ----2.Importing files----\n#reading file\nbikes_path <- \"C:/Users/mosta/Desktop/1/ds_data/01_bike_sales/01_raw_data/bikes.xlsx\"\nbikeshops_path <- \"C:/Users/mosta/Desktop/1/ds_data/01_bike_sales/01_raw_data/bikeshops.xlsx\"\norderlines_path <- \"C:/Users/mosta/Desktop/1/ds_data/01_bike_sales/01_raw_data/orderlines.xlsx\"\nbikes_tbl <- read_excel(bikes_path)\nbikeshops_tbl <- read_excel(bikeshops_path)\norderlines_tbl <- read_excel(orderlines_path)\n\n##----3.Examining data\nglimpse(orderlines_tbl)\n\n#> Rows: 15,644\n#> Columns: 7\n#> $ rownumber   <chr> \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"…\n#> $ order.id    <dbl> 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7…\n#> $ order.line  <dbl> 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2…\n#> $ order.date  <dttm> 2015-01-07, 2015-01-07, 2015-01-10, 2015-01-10, 2015-01-1…\n#> $ customer.id <dbl> 2, 2, 10, 10, 6, 6, 6, 6, 6, 22, 8, 8, 8, 8, 16, 16, 16, 1…\n#> $ product.id  <dbl> 2681, 2411, 2629, 2137, 2367, 1973, 2422, 2655, 2247, 2408…\n#> $ quantity    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1…\n\n##----4.joining data----\nbike_orderlines_joined_tbl <- orderlines_tbl %>%\nleft_join(bikes_tbl,by=c(\"product.id\" = \"bike.id\")) %>%\nleft_join(bikeshops_tbl,by=c(\"customer.id\" = \"bikeshop.id\"))\n\n##---5.Wrangling Data----\nbike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%\n  \n##----6.Business insights----\n\n#6.1.Total sales by category----\n#Separate category name\nseparate(col=category,into=c(\"category.1\", \"category.2\", \"category.3\"),sep=\" - \") %>%\n#Add the total price (price * quantity) \nmutate(total.price=price*quantity) %>%\n#Eliminating the unnecessary columns\nselect(-rownumber,-gender) %>%\n#Reordering the data by selecting the columns in the desired order\nselect(order.id,contains(\"order\"),contains(\"model\"),contains(\"category\"),\n         price,quantity,total.price,everything()) %>%\n#Renaming columns\nrename(bikeshop = name) %>%\nset_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n#6.2.Sales by location----\n##Step1-Manipulate----\nbike_orderlines_tbl <- bike_orderlines_wrangled_tbl %>%\n#Separating location into state and city\nseparate(location,into=c(\"city\",\"state\"),sep = \", \") %>%\n#Selecting columns\nselect(order_date,total_price,state) %>%\n#Grouping by state and summarizing sales\ngroup_by(state) %>%\nsummarize(sales=sum(total_price)) %>%\nungroup() %>%\n#Adding a column for currency format \nmutate(sales_text = scales::dollar(sales,big.mark=\".\",decimal.mark=\",\",prefix =\"\",suffix=\" €\"),\n         max_state=ifelse(sales==max(sales),state,\"\"))\n##Step2-Visualization----\nbike_orderlines_tbl %>%\nggplot(aes(x = state, y = sales, fill = max_state)) +\ngeom_col() +\nscale_fill_manual(values = c(\"#2DC6D6\", \"#FFC700\")) +\ngeom_label(aes(label = sales_text), nudge_y = 1000) +\nscale_y_continuous(labels = scales::dollar_format(big.mark = \".\", decimal.mark = \",\", prefix = \"\", suffix = \" €\")) +\nlabs(title = \"Revenue by State\", subtitle = \"Total Sales\", x = \"State\", y = \"Revenue\") +\ntheme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n2 Tidyverse Challenge-2\n\n#----1.libraries----\nlibrary(tidyverse)\nlibrary(readxl)\n\n# ----2.Importing files----\n#reading file\nbikes_path <- \"C:/Users/mosta/Desktop/1/ds_data/01_bike_sales/01_raw_data/bikes.xlsx\"\nbikeshops_path <- \"C:/Users/mosta/Desktop/1/ds_data/01_bike_sales/01_raw_data/bikeshops.xlsx\"\norderlines_path <- \"C:/Users/mosta/Desktop/1/ds_data/01_bike_sales/01_raw_data/orderlines.xlsx\"\nbikes_tbl <- read_excel(bikes_path)\nbikeshops_tbl <- read_excel(bikeshops_path)\norderlines_tbl <- read_excel(orderlines_path)\n\n##----3.Examining data\nglimpse(orderlines_tbl)\n\n#> Rows: 15,644\n#> Columns: 7\n#> $ rownumber   <chr> \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"…\n#> $ order.id    <dbl> 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7…\n#> $ order.line  <dbl> 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2…\n#> $ order.date  <dttm> 2015-01-07, 2015-01-07, 2015-01-10, 2015-01-10, 2015-01-1…\n#> $ customer.id <dbl> 2, 2, 10, 10, 6, 6, 6, 6, 6, 22, 8, 8, 8, 8, 16, 16, 16, 1…\n#> $ product.id  <dbl> 2681, 2411, 2629, 2137, 2367, 1973, 2422, 2655, 2247, 2408…\n#> $ quantity    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1…\n\n##----4.joining data----\nbike_orderlines_joined_tbl <- orderlines_tbl %>%\nleft_join(bikes_tbl,by=c(\"product.id\" = \"bike.id\")) %>%\nleft_join(bikeshops_tbl,by=c(\"customer.id\" = \"bikeshop.id\"))\n\n##---5.Wrangling Data----\nbike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%\n  \n##----6.Business insights----\n\n#6.1.Total sales by category----\n#Separate category name\nseparate(col=category,into=c(\"category.1\", \"category.2\", \"category.3\"),sep=\" - \") %>%\n#Add the total price (price * quantity) \nmutate(total.price=price*quantity) %>%\n#Eliminating the unnecessary columns\nselect(-rownumber,-gender) %>%\n#Reordering the data by selecting the columns in the desired order\nselect(order.id,contains(\"order\"),contains(\"model\"),contains(\"category\"),\n         price,quantity,total.price,everything()) %>%\n#Renaming columns\nrename(bikeshop = name) %>%\nset_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n#6.2.Sales by location and year----\n##Step1-Manipulate----\nbike_orderlines_tbl <- bike_orderlines_wrangled_tbl %>%\n#Separating location into state and city\nseparate(location,into=c(\"city\",\"state\"),sep = \", \") %>%\n#Extracting year from order_date\nmutate(year=year(order_date)) %>%\n#Selecting columns\nselect(year,state,total_price) %>%\n#Grouping by year and state, and summarizing sales\ngroup_by(year,state) %>%\nsummarize(sales=sum(total_price)) %>%\nungroup() %>%\n#Adding a column for currency format \nmutate(sales_text = scales::dollar(sales,big.mark=\".\",decimal.mark=\",\",prefix=\"\",suffix =\" €\"))\n\n#> `summarise()` has grouped output by 'year'. You can override using the\n#> `.groups` argument.\n\n##Step2-Visualize----\nbike_orderlines_tbl %>%\nggplot(aes(x=year, y=sales, fill=state)) + geom_col() +\nscale_y_continuous(labels=scales::dollar_format(big.mark = \".\", decimal.mark = \",\", prefix = \"\", suffix = \" €\")) +\nlabs(title=\"Revenue by State and Year\", subtitle=\"Total Sales\", x=\"Year\", y=\"Revenue\") +\nfacet_wrap(~state, ncol=4) +\ntheme(axis.text.x=element_text(angle=45,hjust=1))"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "1 Data Acquisition Challenge-1\n\n##----1.libraries----\nlibrary(rvest)\nlibrary(tibble)\nlibrary(httr)\nlibrary(ggplot2)\n\n##----2.read the data----\nurl <- \"https://www.boxofficemojo.com/year/world/2022/\"\nresp <- GET(url)\nhtml <- content(resp)\n\n##----3.Top 10 Movies by Sales-2022----\n\n#3.1.Getting the rank----\nrank <- html %>% \n  html_nodes(\".a-text-right.mojo-header-column.mojo-truncate.mojo-field-type-rank.mojo-sort-column\") %>% \n  html_text() %>% \n  as.numeric()\n\n#3.2.Getting the title----\ntitle <- html %>% \n  html_nodes(\".a-text-left.mojo-field-type-release_group a\") %>% \n  html_text()\n\n#3.3.Getting the number of sales----\nsale <- html %>%\n  html_nodes(\"td.a-text-right.mojo-field-type-money\") %>%\n  html_text() \n\n#3.4.Creating a tibble----\nmovie_tbl <- tibble(\n  rank = rank[1:10], \n  title = title[1:10], \n  sale = sale[1:10])\nmovie_tbl\n\n\n\n  \n\n\n#3.6.A bar plot for the sales----\nggplot(movie_tbl, aes(x = title, y = sale)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Movie Title\", y = \"Sales\") +\n  ggtitle(\"Top 10 Movies by Sales (2022)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n2 Data Acquisition Challenge-2\n\n##----.Libraries\nlibrary(tidyverse)\nlibrary(rvest)\n\n##----1.Read in the HTML for the entire webpage of the \"bikes\" section----\nhtml_family <- read_html(\"https://www.rosebikes.com/bikes/\")\n\n#1.1.Web scrape the URLs for each bike family\nbike_family_tbl <- html_family %>%\n  html_nodes(css = \".catalog-navigation__list .catalog-navigation__list-item .catalog-navigation__link\") %>%\n  html_attr(\"href\") %>%\n  str_replace_all(\"^/\", \"https://www.rosebikes.com/\") %>%\n  as_tibble() %>%\n  rename(URL = value)\n\n#1.2.Print the tibble of the URLs\nbike_family_tbl\n\n\n\n  \n\n\n##----2.Read in the HTML for the entire webpage of the \"family\" section----\nbike_subfamily_url <- bike_family_tbl$URL[2]\nhtml_subfamily <- read_html(bike_subfamily_url)\n\n#2.1.Web scrape the URLs for \"Road\" bike subfamily\nbike_subfamily_tbl <- html_subfamily %>%\n  html_nodes(css = \".catalog-category-bikes__picture-wrapper.columns.small-12.medium-6.mediumlarge-7.large-8.catalog-category-bikes__picture-wrapper--left\") %>%\n  html_attr(\"href\") %>%\n  {glue(\"https://www.rosebikes.com{.}\")} %>%\n  as_tibble() %>%\n  rename(URL = value)\n\n#2.2.Print the tibble of the URLs\nbike_subfamily_tbl\n\n\n\n  \n\n\n##----3.Read in the HTML for the entire webpage of the \"xlite\" category section----\nbike_category_url <- bike_subfamily_tbl$URL[1]\nhtml_category <- read_html(bike_category_url)\n\n#3.1.Extract bike name of \"xlite\" category\nname <- html_category %>%\n  html_nodes(css = \".basic-headline.basic-headline--no-margin.basic-headline--small.basic-headline--left .basic-headline__title\") %>%\n  html_text() \n\n#3.2.Extract bike price of \"xlite\" category and remove non-numeric characters\nprice <- html_category %>%\n  html_nodes(css = \".product-tile-price__current.catalog-category-model__price-current .product-tile-price__current-value.catalog-category-model__price-current-value\") %>%\n  html_text() %>%\n  gsub(\"[^0-9.]\", \"\", .) # remove non-numeric characters\n\n#3.3.Create tibble of the bikes in \"xlite\" category and format the price\nbike_category_tbl <- tibble(name = name, price = glue(\"{gsub(',', '', gsub('€', '', price))}\"))\n\n#3.4.Print tibble\nbike_category_tbl"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "1 Data Wrangling Challenge-1\n\n##----.libraries----\nlibrary(data.table)\nlibrary(dplyr)\n\n##----1.Read and combining the data----\npatent_assignee_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/patent_assignee.tsv\"\nassignee_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/assignee.tsv\"\npatent_assignee_data <- fread(patent_assignee_file)\nassignee_data <- fread(assignee_file)\ncombined_data <- merge(patent_assignee_data, assignee_data, by.x = \"assignee_id\", by.y = \"id\")\n\n##----2.Count the number of patents granted to each US company----\nus_company_patents <- combined_data %>%\n  filter(type == 2) %>%\n  group_by(organization) %>%\n  summarize(patent_count = n()) %>%\n  ungroup() %>%\n  arrange(desc(patent_count))\n\n#----3.List the top 10 US companies with the most new granted patents----\ntop_10_companies <- head(us_company_patents, 10)\nprint(top_10_companies)\n\n#> # A tibble: 10 × 2\n#>    organization                                patent_count\n#>    <chr>                                              <int>\n#>  1 International Business Machines Corporation         7547\n#>  2 Microsoft Corporation                               3165\n#>  3 Google Inc.                                         2668\n#>  4 QUALCOMM Incorporated                               2597\n#>  5 Apple Inc.                                          2201\n#>  6 General Electric Company                            1873\n#>  7 Hewlett-Packard Development Company, L.P.           1638\n#>  8 AT&T INTELLECTUAL PROPERTY I, L.P.                  1625\n#>  9 Intel Corporation                                   1616\n#> 10 GM Global Technology Operations LLC                 1533\n\n\n\n2 Data Wrangling Challenge-2\n\n##----.libraries----\nlibrary(data.table)\nlibrary(dplyr)\n\n##----1.Read the data----\npatent_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/patent.tsv\"\npatent_assignee_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/patent_assignee.tsv\"\nassignee_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/assignee.tsv\"\npatent_data <- fread(patent_file)\npatent_assignee_data <- fread(patent_assignee_file)\nassignee_data <- fread(assignee_file)\n\n##----2.Jcombine and filter the data to get the assignee information for August 2014 patents----\naugust_patents <- patent_data[month(date) == 8 & year(date) == 2014]\ncombined_data <- merge(merge(august_patents, patent_assignee_data, by.x = \"id\", by.y = \"patent_id\", all.x = TRUE),\n                       assignee_data, by.x = \"assignee_id\", by.y = \"id\", all.x = TRUE)\n\n##----3.Count the number of patents granted to each US company in August 2014----\nus_company_patents <- combined_data %>%\n  filter(type == 2) %>%\n  group_by(organization) %>%\n  summarize(patent_count = n()) %>%\n  ungroup() %>%\n  arrange(desc(patent_count))\n\n#----4.List the top 10 US companies with the most new granted patents for August 2014----\ntop_10_companies <- head(us_company_patents, 10)\ntop_10_companies\n\n\n\n  \n\n\n\n\n3 Data Wrangling Challenge-3\n\n##----.libraries----\nlibrary(data.table)\nlibrary(dplyr)\n\n##----1.Read and combine the data----\npatent_assignee_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/patent_assignee.tsv\"\nassignee_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/assignee.tsv\"\nuspc_file <- \"C:/Users/mosta/Desktop/3/Patent_data_reduced/uspc.tsv\"\npatent_assignee_data <- fread(patent_assignee_file)\nassignee_data <- fread(assignee_file)\nuspc_data <- fread(uspc_file)\ncombined_data <- merge(patent_assignee_data, assignee_data, by.x = \"assignee_id\", by.y = \"id\")\n\n##----2.Count the number of patents granted to each company worldwide----\ncompany_patents <- combined_data %>%\nfilter(!(is.na(organization))) %>%\ngroup_by(organization) %>%\nsummarize(patent_count = n()) %>%\nungroup() %>%\narrange(desc(patent_count))\n\n##----3.The top 10 companies with the most patents----\ntop_10_companies <- head(company_patents, 10)$organization\ntop_10_companies\n\n#>  [1] \"International Business Machines Corporation\"\n#>  [2] \"Samsung Electronics Co., Ltd.\"              \n#>  [3] \"Canon Kabushiki Kaisha\"                     \n#>  [4] \"Sony Corporation\"                           \n#>  [5] \"Microsoft Corporation\"                      \n#>  [6] \"Google Inc.\"                                \n#>  [7] \"Kabushiki Kaisha Toshiba\"                   \n#>  [8] \"QUALCOMM Incorporated\"                      \n#>  [9] \"LG Electronics Inc.\"                        \n#> [10] \"Panasonic Corporation\"\n\n##----4.Filter the combined_data for the top 10 companies----\nfiltered_data <- combined_data[organization %in% top_10_companies]\n\n##----5.Join the filtered_data with the uspc table----\nfiltered_uspc <- merge(filtered_data, uspc_data, by.x = \"patent_id\", by.y = \"patent_id\")\n\n##----6.Count the occurrences of each main class for the top companies----\ntop_main_classes <- filtered_uspc %>%\n  group_by(mainclass_id) %>%\n  summarize(occurrences = n()) %>%\n  arrange(desc(occurrences)) %>%\n  head(5)\n\ntop_main_classes"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "1 Data Visualization Challenge-1\n\n##----.libraries----\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\n\n##----1.Read the data----\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 311447 Columns: 67\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n##----2.Filter data for date and countries----\nfiltered_data <- covid_data_tbl %>%\n  filter(location %in% c(\"Germany\", \"United Kingdom\", \"France\", \"Spain\", \"United States\")) %>%\n  filter(date <= ymd(\"2022-04-19\"))%>%\n  filter(!is.na(total_cases))\n\n##----3.Plot----\ncolors <- c(\"Germany\" = \"purple\", \"United Kingdom\" = \"green\", \"France\" = \"orange\",\n            \"Spain\" = \"pink\", \"United States\" = \"yellow\")\n\nus_cases <- max(filtered_data$total_cases[filtered_data$location == \"United States\" & !is.na(filtered_data$total_cases)])\n\nggplot(filtered_data, aes(x = date, y = total_cases, color = location)) +\n  geom_line(size = 1) +\n  scale_color_manual(values = colors) +\n  labs(x = \"\", y = \"Cumulative Cases\", title = \"COVID-19 confirmed cases worldwide\", subtitle = \"As of 19/04/2022\") +\n  scale_x_date(\n    date_labels = \"%B'%y\",\n    date_breaks = \"1 month\",\n    labels = function(x) format(x, format = \"%B'%y\")\n  ) +\n  scale_y_continuous(\n    labels = function(x) paste0(format(x / 1e6, scientific = FALSE), \"M\"),\n    breaks = c(0, 50e6, 100e6, 150e6),\n    limits = c(0, 150e6)\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.background = element_rect(fill = \"darkgrey\")\n  ) +\n  labs(color = \"Country\") +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels\n    axis.ticks.x = element_blank()\n  ) +\n  geom_label(\n    data = filtered_data %>% filter(location == \"United States\" & total_cases == us_cases),\n    aes(\n      x = date, y = total_cases,\n      label = paste0(format(us_cases, scientific = FALSE, big.mark = \".\", decimal.mark = \",\"))\n    ),\n    fill = \"red\",\n    color = \"white\",\n    fontface = \"bold\",\n    label.padding = unit(0.5, \"lines\"),\n    label.size = 0.15,\n    label.r = unit(0.15, \"lines\")\n  )\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n2 Data Visualization Challenge-2\n\nlibrary(tidyverse)\nlibrary(maps)\n\n##----1.Access the data----\nworld <- map_data(\"world\")\n\n##----2.Read the data----\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 311451 Columns: 67\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndate_to_filter <- as.Date(\"2021-04-16\")\n\n##----3.Calculation of mortality rate----\nplot_data <- covid_data_tbl %>%\n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n  )) %>%\n  filter(date <= as.Date(\"2022-04-19\")) %>%\n  filter(!(is.na(continent))) %>%\n  group_by(location) %>%\n  summarize(deaths_on_that_date = sum(new_deaths[date <= as.Date(\"2022-04-19\")], na.rm = TRUE),\n            population_on_that_date = population[date == as.Date(\"2022-04-19\")],\n            mortality_rate = deaths_on_that_date * 100 / population_on_that_date)\n\n##----4.Calculate total deaths worldwide because we need it in the subtitle----\ndeaths_worldwide_on_that_date <- round(sum(plot_data$deaths_on_that_date, na.rm = TRUE) / 1e6, digits = 1)\n\n##----5.Add missing regions from the plot to be shown as the gray part (for example Antarctica) to the data----\nmissing_regions <- world$region[!(world$region %in% plot_data$location)]\nmissing_data <- tibble(location = missing_regions,\n                       deaths_on_that_date = NA,\n                       population_on_that_date = NA,\n                       mortality_rate = NA)\nplot_data <- bind_rows(plot_data, missing_data)\n\n##----6.Plot----\nggplot(plot_data, aes(map_id = location)) +\n  geom_map(aes(fill = mortality_rate), map = world) +\n  expand_limits(x = world$long, y = world$lat) +\n  scale_fill_gradient(low = \"red\", high = \"black\", na.value = \"gray\", breaks = c(0.20, 0.40, 0.60), labels = c(\"0.20%\", \"0.40%\", \"0.60%\")) +\n  labs(title = \"Confirmed COVID-19 deaths relative to the size of the population\",\n       subtitle = paste0(\"Around \", deaths_worldwide_on_that_date, \" Million\", \" confirmed COVID-19 deaths worldwide\"),\n       fill = \"Mortality Rate\") +\n  theme_void() +\n  annotate(\n    \"text\",\n    x = max(world$long) - 2,\n    y = min(world$lat) + 1,\n    label = \"Date: 04/16/2021\",\n    hjust = 1,\n    vjust = 0,\n    size = 4,\n    color = \"black\"\n  )"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  }
]